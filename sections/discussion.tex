\chapter{Discussion} \label{cha: discussion}

\section{Data}
In this project, publicly available person \acs{ReID} datasets were used, due to strict privacy regulations regarding personal data. This higlights a common challenge in the \acs{ReID} field, specifically that these existing datasets often reflect specific cultural, environmental, and geographic contexts. For example the Market-1501, CUHK03, and MSMT17 datasets are all recorded at different universities in different regions of China, while the DukeMTMC-ReID dataset is recorded at a University in North Carolina, USA. This introduces a potential cultural bias toward the appearance and behavior of university students, as well as a geographical bias, since all of the data is collected from campus environments. Moreover, the majority of the data originates from China, which may limit the models generalizability to populations in other countries. The ILIDS-VIDS dataset is captured at an airport in the United Kingdom, which introduces an entirely different environment. It includes challenges such as occlusions, crowding, carrying luggage, varying clothing styles, and is solely in an indoors environment. This makes it valuable for testing generalization beyond university settings. 
\\\\
The data was split so that the models were trained on the Market-1501, MSMT17, and CUHK03 datasets, and final testing was performed on the ILIDS-VID and DukeMTMC-ReID datasets. This design creates a cross-domain evaluation setup, which is useful for assessing generalization. However, it also introduces a domain mismatch. The model is trained to identify university students on campuses in China, and then tested on different demographic groups in the forms of university students on campus in the USA, and more diverse people inside of an airport. This mismatch likely impacts performance, and raises questions about the fairness and robustness of the system in deployment scenarios. 
\\\\
Furthermore, the datasets are not balanced in size. For example the MSMT17 dataset contains almost three times more identities and nearly ten times more images than CUHK03, which may cause the model to overfit to the dominant dataset and under-represent features from the smaller datasets. In future work, a more structured training strategy could be explored, such as training on each dataset separately, balancing datasets in each batch, or incorporating datasets with diverse cultural, environmental and geographical conditions during training, to improve cross-domain generalization and fairness. 
\\\\
Finally it is important to note that the datasets represent relative controlled environments, with no cases of extreme weather, very low-light conditions, or highly crowded events, which are expected to appear in real-world surveillance footage. 

\subsubsection{Data Augmentations}
Data-augmentation is applied to improve model generalizability, by introducing diversity and simulating real-world circumstances. The augmentation pipeline is as follows:
\begin{itemize}
    \item Normalization 
    \item JPEG compression
    \item Horizontal flipping
    \item Gaussian blur
    \item Gaussian noise
    \item Brightness change
    \item Resizing
    \item Padding
\end{itemize}

\noindent These augmentations were selected with the purpose of improving model performance. JPEG compression is used to simulate the quality loss often seen in real-world surveillance footage, caused by camera hardware and storage limitations. Standard flipping was used to inflate data. Only horizontal flipping was applied, as vertical flipping would not add meaningful information for the real-word domain of \acs{ReID}. Gaussian blur and noise were applied to simulate visual degradation caused by environmental conditions or surveillance hardware. Brightness change was used to simulate lighting conditions at different times of the day. The images were also resized to different scales, and filled with black padding, to simulate variations in distance and camera quality. Padding is only used to secure that the tensors are the same size for stacking. Overall. The augmentations fulfill their purpose and are appropriate for the domain, but datasets with real degradations and a clean ground truth should be used if available. 
\\\\
Despite this, if all the augmentations happened to be applied heavily to a single image, quality may degrade to a point where it is too difficult for the model to extract meaningful features. This highlights the importance of balancing data augmentation, so realism is preserved without compromising the visual information. During implementation, the Python \texttt{random} library was used to apply random transformations. However, it would have been more appropriate to use PyTorch's own random functions, as they share the same seeding used throughout the framework, and are compatible with GPU training. This ensures better reproducibility and consistency across experiments, especially when using multiple workers and different hardware setups. 

\subsubsection{OOD Dataset}
The OOD dataset consists of different augmented versions of the DukeMTMC-Reid dataset, and the iLIDS-VID dataset. The





\section{Experiments}
- Hvordan kan OSNet træne deres model med en learningrate på 0.065 når vi ikke engang kunne på 0.032? 
- Hvorfor tror vi resultaterne bliver som de gør? eg. hvorfor er det ikke nok bare at træne en robust osnet. 
- Hvorfor er det bedre at træne joint?

\section{Results}

\subsection{OSNet}
Hvad fik vi ud af at bruge cross-entropy loss fremfor triplet loss? (nemmere kode, nødvendigt grundet deadline)

\subsubsection{Baseline}
Opnåede vi det vi ville med baseline, er den lavet så den er fair til at bruge til sammenligning?

\subsubsection{Augmentated}

\subsection{EDSR}
Var EDSR et godt valg? 

\subsubsection{EDSR}

\subsection{Sequential EDSR and Baseline}
Implementing both models sequentially effectively meant that only \acs{OSNet} had the chance to improve. By only inputting the \acs{HR} \acs{ReID} image, \acs{EDSR} could not learn more than it already knew about general upscaling. \acs{OSNet} learned how to extract useful embeddings from \acs{SR} images. Der skal mere til men pas lige nu.

\subsection{Joint EDSR and Baseline}
%Hvorfor implementeret  på den måde - hvad med auxilary loss?
The joint implementation of the \acs{EDSR} and \acs{OSNet} models served it's purpose as intended. The combined forward pass allowed \acs{EDSR} to learn from \acs{OSNet}'s loss, and thereby specialize the upscaling to assists in better embeddings. However, having no \acs{SR} specific loss, limited this ability. Implementing an auxillary loss, by inputting downscaled \acs{ReID} data, and comparing it to the original \acs{HR} data, could have improved performance. Therefore this addition should be considered for future work. 

\section{Deployment}

The choice to cloud-deploy the system, is based on ethical considerations. If the system is incorporated directly into local hardware, it would be implied that the captured footage is constantly being analyzed in real time. Such a design effectively normalizes monitoring the citizens at all times, in line with the definition of a surveillance state. Furthermore, when the system is embedded in local hardware, it becomes more difficult to regulate and monitor how and by whom it is used, increasing the risk of misuse or unauthorized access.
\\\\
On the contrary, if the system is deployed in the cloud, it remains inactive until invoked for a specific purpose. This ensures that footage is not automatically processed unless it is necessary and that access can be controlled through authentication and logs.
\\\\
However, cloud deployment is not without limitations. It requires a stable and secure internet connection, that enables safe transmission of sensitive data, though this risk can be mitigated through encryption. An alternative deployment strategy could be XXX.
 

\section{Ethical Considerations}
%Hvilke ethical constrains har vi haft på vores system?
The development and deployment of person \acs{ReID} systems raises several ethical concerns. These concerns are defined and discussed as follows:
\\\\
These systems handle sensitive visual data of individuals, often without their explicit consent, which can impact the right to privacy, and freedom of movement. Therefore, ethical constrains were considered in the design and deployment phase. %lidt gentagelse imo

\subsubsection{Privacy and Consent}
Surveillance of public areas challenges the concept of informed consent, as individuals are often unaware of the monitoring, and do not have the choice of not being recorded. Therefore, such footage must be handled carefully, and person \acs{ReID} systems should be designed to only be activated when specific requirements are met, such as for the purpose of investigating crime. 

\subsubsection{Transparency}
The public should be informed about where, how, and why person \acs{ReID} systems are used. The cloud deployment strategy supports transparency as it allows for monitoring the usage of the systems. 

\subsubsection{Misuse}
One of the more serious issues regarding person \acs{ReID} systems is the potential for misuse. In the wrong hands, such a system can be used to target innocent people based on their race, religion, or political opinions. It can also be used in a surveillance state, which negatively impacts the citizens freedom of speech and freedom of movement. This risk is reduced through the use of authentication and logs.

\subsubsection{Data Security}
As the system handles potentially sensitive data, it is important to ensure data security. This can be done through encryption, and should be applied when storing the data as well as for transmitting the data. Furthermore, data should only be kept for as long as necessary, with access limited to authorized and relevant personnel. 


\section{Future Work}
Hvad mangler det for at blive realiseret system?

- The gap between training data and deployment environments should be addressed in future works. 