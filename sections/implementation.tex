\chapter{Implementation} \label{cha: implementation}
This Chapter presents the implementation of the SR and ReID together with the overall implementation choices.

\section{Dataloaders}
\label{imp_dataloading}
Both of the data loaders are built using the Dataset and DataLoader classes from torch.utils.data. They are designed to generate batches of data samples for training, validation and test. Special for the \ac{ReID} data loader is that validation and test is split into query and gallery splits. 
\\\\
For the \ac{ReID} datasets, three datasets are used for training: MSMT17, Market1501 and CUHK03. The data loader is combining these datasets, enabling joint training across all of them. To prevent any person-id conflict, in case where the same person-id is appearing in multiple dataset, and ensure continues id-values a json file with mappings is created. This maps from the old id, with a dataset specific prefix in front, to a new continues value. It ensures that all person IDs remain unique across dataset, while preserving person-id for each person and introducing continues values for which a softmax can be trained on. In the process of creating the json file, every 10th new person-id are pulled into a validation set. In the data loader, one sample per person ID is added to the query set. The remaining samples are categorized for the gallery set: any sample that does not match both the person-ID and camera-ID of the query sample is added to the gallery.
\\\\
The data loader for the SR datasets simply splits the images into input and target images, and creates batches. The images from DIV2K and RELLISUR dataset are kept separate.

\section{Dataaugmentation} \label{sec: dataaugmentation}
A classic way to improve performance and generalization is through augmentations. The goal is to improve model performance in terms of generalization across different image scales and resolution, and robustness in real life scenarios. The different types of augmentation and their purpose is included in Table \ref{tab:augmentationtypes}.
\begin{table}[H]
    \centering
    \begin{tabular}{|>{\centering\arraybackslash}p{0.18\linewidth}|>{\centering\arraybackslash}p{0.78\linewidth}|}\hline
         \cellcolor[HTML]{D8E9F7} \textbf{Augmentation}&  \cellcolor[HTML]{D8E9F7} \textbf{Purpose}\\\hline
         Normalization&  Standardize pixel intensity values to improve training.\\\hline
         Vertical flipping&  Increase size bigger dataset.\\\hline
 Gaussian blur&Improve robustness to low-quality and blured images.\\\hline
 Gaussian noise&Enhance generalization to imperfect and noisy images.\\\hline
 Brightness change&Increase resilience to varying lighting conditions.\\\hline
 Resizing&Introduces scale variation by randomly reducing the image size with a scale between 0.5 and 1 and then padding back to the target dimensions. Resizing using bilinear interpolation.\\\hline
 Padding& Secure that tensor sizes is the same in order to be stacked.\\\hline
 JPEG compression& Improve robustness to compression noise, simulating compression from surveillance footage.\\ \hline
    \end{tabular}
    \caption{The different augmentations implemented.}
    \label{tab:augmentationtypes}
\end{table}
\noindent These data augmentations are used in three different transformation pipelines: One with light augmentations, one with strong augmentations, and one for evaluations, see Table \ref{tab:three_subtables}
\begin{table}[H]
\centering
\begin{subtable}[T]{0.32\linewidth}
\centering
\begin{tabular}{|>{\centering\arraybackslash}p{0.9\linewidth}|}\hline
\cellcolor[HTML]{D8E9F7} \textbf{Light Training Augmentation}\\\hline
\begin{itemize}[leftmargin=*, topsep=0pt, itemsep=0pt]
    \item Normalization
    \item Vertical flipping
    \item Padding, if to small
    \item Resizing, if to big
    \vspace{6.1em}
\end{itemize}
\\ \hline\end{tabular}
\caption{Augmentations used for baseline version of OSNet.}
\end{subtable}
\hfill
\begin{subtable}[T]{0.32\linewidth}
\centering
\begin{tabular}{|>{\centering\arraybackslash}p{0.9\linewidth}|}\hline
\cellcolor[HTML]{D8E9F7} \textbf{Strong Training Augmentation}\\\hline
\begin{itemize}[leftmargin=*, topsep=0pt, itemsep=0pt]
    \item Gaussian noise
    \item Gaussian Blur
    \item Brightness change
    \item Resizing
    \item JPEG compression
    \item Normalization
    \item Vertical flipping
    \vspace{1em}
\end{itemize}
\\ \hline\end{tabular}
\caption{Augmentation used for augmentation version of OSNet.}
\end{subtable}
\hfill
\begin{subtable}[T]{0.32\linewidth}
\centering
\begin{tabular}{|>{\centering\arraybackslash}p{0.9\linewidth}|}\hline
\cellcolor[HTML]{D8E9F7} \textbf{Evaluation Preprocessing}\\\hline
\begin{itemize}[leftmargin=*, topsep=0pt, itemsep=0pt]
    \item Normalization
    \vspace{11em}
    \vspace{1mm}
\end{itemize}
\\ \hline\end{tabular}
\caption{Augmentation used for validation and test sets.}
\end{subtable}

\caption{The three different augmentations pipelines.}
\label{tab:three_subtables}
\end{table}
\noindent The three augmentations pipelines will be used in Chapter \ref{cha: experiments}.

\section{Implementation of OSNet}
%Note: vi bruger x1 modellen, som er den største. 
The architecture of the person \acs{ReID} model that is implemented is the same as described in Section \ref{lab:methodreid}. The \acf{OSNet} implementation is taken from the \texttt{Torchreid} library, which comes with a pretrained \acs{OSNet} model. However, to ensure full control over the training process and to train from scratch, a custom training script is made. 
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}\hline
        \cellcolor[HTML]{D8E9F7} \textbf{Parameter} & \cellcolor[HTML]{D8E9F7} \textbf{Value} \\\hline
        Number of classes (\texttt{num\_classes}) & \texttt{num\_classes} \\\hline
        Block types (\texttt{blocks})             & [\texttt{OSBlock}, \texttt{OSBlock}, \texttt{OSBlock}] \\\hline
        Layers per stage (\texttt{layers})        & [2, 2, 2] \\\hline
        Channels per stage (\texttt{channels})    & [64, 256, 384, 512] \\\hline
        Loss function (\texttt{loss})             & \texttt{loss parameter ('softmax' or 'triplet'} \\\hline
    \end{tabular}
        \caption{OSNet\_x1\_0 Configuration.}
    \label{tab:osnet-config}
\end{table}

\subsubsection{Model Configuration}
The \acs{OSNet} x1 variant is used, which is the largest base \acs{OSNet} model with 2.2 million parameters. As shown in Table \ref{tab:osnet-config} the model consists of three stages of OSBlocks using channel configurations of [64, 256, 384, 512]. The model initialize with random weights (pretrained=False) rather then using pretrained ensuring that the model learns features specially relevant to the combined datasets.

\subsubsection{Training Setup}
The model is trained on the combination of Market-1501, MSMT17 and CUHK03 train split, resulting in 2,117 unique identities. The person ID mapping strategy described in Section \ref{imp_dataloading} ensures that identities remain unique across the combined dataset and preventing ID conflicts between datasets, while ensuring a continues range of id, optimal for training using softmax.

\subsubsection{Hyperparameters}
The complete set of training hyperparameters is presented in Table \ref{tab:osnettrainingparameters}. The model is trained by using \ac{SGD} with momentum of 0.9 and weight decay of 0.0005  for regularization. The initial learning rate is set to 0,001. The loss function used is CrossEntropyLoss with a label smoothing of 0.1. Label smoothing is a regularization technique that prevents the model for becoming overconfident in its predictions by softening the target labels. Instead of using one-hot encoded labels. This is particularly beneficial for person ReID, as it addresses the challenge of limited training samples per identity. By preventing extreme confidence on training identities, label smoothing encourages the model to learn more robust features that generalize better to unseen test identities.  ********

A \texttt{MultiStepLR} scheduler controls the learning rate throughout training, reducing it by a factor of 0.1 at epoch 60, 120, and 180. The results of the learning rate schedule:

\begin{itemize}
    \item Epochs 0-100: LR =0.001
    \item Epochs 100 - 174 LR = 0.0001
    \item Epochs 175 - 224 LR = 0.00001
    \item Epochs 225 - 350 LR = 0.000001

\end{itemize}
Training runs for a total of 350 epochs without early stopping, though the best 

\subsubsection{Loss Function and Label Smoothing}


\subsubsection{Validation Strategy}
The models performance is monitored through periodic validation:
\begin{itemize}
    \item For epochs 1 - 200: validation is performed every 10 epoch
    \item For epochs 201 - 350: validation frequency increases to every 5 epoch
\end{itemize}

This adaptive validation strategy allows for more frequent monitoring as the training and the model approaches convergence.

%Info om LR, Få mere info i næste afsnit.
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}\hline
         \cellcolor[HTML]{D8E9F7} \textbf{Training Hyperparameter}&  \cellcolor[HTML]{D8E9F7} \textbf{Value}\\\hline
         Nos. Images &  2117\\\hline
         Nos. epochs &  350\\\hline
         Batch Size &  64 \\\hline
         Optimizer &  SGD \\\hline
         Momentum&0.9\\\hline
         Weight Decay&0.0005\\\hline
         Learning Rate Scheduler &\texttt{MultiStepLR}\\\hline
         Learning Rate & 0.001\\\hline
         LR Milestones&  [100, 175, 225]\\\hline
         LR Gamma&  0.1\\\hline
         Optimizer &  SGD \\\hline
         Loss Function&  CrossEntropyLoss\\\hline
         
 Label Smoothing&0.1\\ \hline
    \end{tabular}
    \caption{The training hyperparameters and their value for training the OSNet.}
\label{tab:osnettrainingparameters}
\end{table}

\subsubsection{Batch Size Considerations}


\section{Implementation of EDSR}
% henvis gerne til related works om SR hvor EDSR nævnes, eller "Perception-distortion trade-off", samt dens appendix. Ud fra det kan vi bruge argumentet at EDSR har meget lav distortion, sammenlignet med andet, og derfor giver et godt udgangspunkt i forlængelse af ReID.
\begin{table}[H]
    \centering
    \caption{Baseline EDSR configuration.}
    \label{tab:edsr-config}
    \begin{tabular}{|c|c|}\hline
        \cellcolor[HTML]{D8E9F7}\textbf{Parameter} & \cellcolor[HTML]{D8E9F7}\textbf{Value} \\\hline
        Number of residual blocks (\texttt{n\_resblocks}) & 16 \\\hline
        Number of feature maps (\texttt{n\_feats})        & 64 \\\hline
        Upscaling factor (\texttt{scale})                 & [2] \\\hline
        Number of input colors (\texttt{n\_colors})       & 3 \\\hline
        Residual scaling factor (\texttt{res\_scale})     & 0.1 \\\hline
    \end{tabular}
\end{table}

\section{Implementation of Sequential ReID and SR}
To fully asses the impact of implementing a \ac{SR} system with \ac{ReID} a script was created to evaluate a sequential combination of the two models, where the data is first passed through the trained \ac{SR} model, whose output is then fed into the trained \ac{ReID} model. The efficiency of this setup is expressed with error metrics mAP and Rank-1, and can then be compared with other evaluation instances, such as the same \ac{ReID} model without the \ac{SR}. 
\\\\
This sequential evaluation script is made to test both \ac{ReID} alone and also in combination with \ac{SR}. It has been specifically made to fit only the OSNet and EDSR structure, as those are the main models used in this project. The dataloader discussed in \ref{imp_dataloading} has also been used in conjunction with this script, but mostly with a distinct emphasis on the evaluation part, such as query and gallery for the relevant \ac{ReID} datasets. 
% Noget om forskellige sr scales prøvet. Batch sizes, num workers?
% Baseline models tested (off the shelf måske?)
% Den wrap ved "class IntPidCamDataset" kan også forklares hvis det er.
% Noget om feature extraction måske?
% Noget om alle de forskellige args?




\section{Implementation of Joint ReID and SR}
Since the \ac{SR} module is trained to upscale images, it is not specialized for the task of person \ac{ReID}. By combining the two modules end-to-end, the \ac{ReID} loss can flow back into the \ac{SR} module, forcing it to learn specific upscaling and cleaning operations which improve the final \ac{ReID} task. 
\\\\
To combine the two modules end to end, each model was downloaded from it’s respective github repository. The models were then wrapped in a function which builds the model with the configuration befitting it’s size. OSNet configuration can be seen in Table \ref{tab:osnet-config}, EDSR configuration can be seen in Table \ref{tab:edsr-config}.

\noindent To allow for losses to backpropagate through both modules, a new class was created with a combined forward pass. The forward pass takes an image as input, forwards it through the \ac{SR} module first and then through the \ac{ReID} module, with the option of also returning the \ac{SR} output to increase operation transparency. The class also allows for each module to be initated with frozen weights, such that the possibility of the \ac{SR} module becoming a \ac{ReID} feature extractor is minimized. The frozen module can then be unfrozen with an unfreeze function.